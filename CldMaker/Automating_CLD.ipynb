{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVrvrnwMUV7v"
   },
   "source": [
    "# Download Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qcbSXGv2BgP9",
    "outputId": "319483df-59d1-4efa-fcda-e0ada2ce35b9",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!apt install python3-dev graphviz libgraphviz-dev pkg-config\n",
    "!pip install langchain pygraphviz google-search-results\n",
    "!pip install google-cloud-aiplatform --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LdXDL1HbVRsQ",
    "outputId": "ce4485cc-9a06-4210-beed-c39dca2c7f5a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xT4_hy_UZ7y"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdBdwyOWCydh",
    "outputId": "e32edecd-56df-4e96-cdbf-69748699b829",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "#\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlQ8DNiNMeFu",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# SHEET_NAME = 'Sheet1'\n",
    "# URL = 'https://docs.google.com/spreadsheets/d/1u_Mddcwgl5rULHOHPjIFciaf5_ZriKHVXW96xrN-JpU/edit#gid=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TvqQ4QdZA4RS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 14:27:48.687805: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from typing import List, Dict, Tuple, Any, Optional, Union\n",
    "# from PIL import Image\n",
    "\n",
    "# from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "# from google.colab import auth as google_auth\n",
    "# google_auth.authenticate_user()\n",
    "#\n",
    "# import gspread\n",
    "# from gspread_dataframe import set_with_dataframe\n",
    "# from google.auth import default\n",
    "#\n",
    "# creds, _ = default()\n",
    "# gc = gspread.authorize(creds)\n",
    "#import vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "#from langchain.llms import VertexAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain, TransformChain, SequentialChain\n",
    "from langchain.evaluation.criteria.eval_chain import CriteriaEvalChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcPjUwyWR8yW"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ouhD22VJCKqk"
   },
   "outputs": [],
   "source": [
    "config =[\n",
    "    {\n",
    "        'input_variables':['dynamic_hypothesis'],\n",
    "        'output_variables':['variables'],\n",
    "        'prompt_prefix':'''\n",
    "        Render a list of variable names from the text given.\n",
    "\n",
    "        The variable names in\n",
    "        '''\n",
    "        ###Write up\n",
    "    },\n",
    "    {\n",
    "        'input_variables':['variables','dynamic_hypothesis'],\n",
    "        'output_variables':['label_graphs'],\n",
    "        'prompt_prefix':'''\n",
    "        Render a dot format of variable names from the text given.\n",
    "\n",
    "\n",
    "        '''\n",
    "        ###Write up\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wkMzrxZsDhWi"
   },
   "outputs": [],
   "source": [
    "def make_few_shot_prompt(\n",
    "    input_variables: List[str],\n",
    "    output_variables:List[str],\n",
    "    prompt_prefix: str,\n",
    "    examples_df: pd.DataFrame,\n",
    "    variable_delimiter: str,\n",
    ")-> FewShotPromptTemplate:\n",
    "\n",
    "  all_variables = input_variables+ output_variables\n",
    "\n",
    "  few_shot_prompt = FewShotPromptTemplate(\n",
    "      examples = examples_df[all_variables].to_dict('records'),\n",
    "      example_prompt = PromptTemplate(\n",
    "          input_variables=all_variables,\n",
    "          template = f'{variable_delimiter}\\n'.join([f'{v}:{{{v}}}'\n",
    "                                                  for v in all_variables]),\n",
    "      ),\n",
    "      prefix = prompt_prefix,\n",
    "      suffix = f'{variable_delimiter}\\n'.join([f'{v}:{{{v}}}'for v in input_variables]),\n",
    "      input_variables = input_variables,\n",
    "  )\n",
    "  return few_shot_prompt\n",
    "\n",
    "def make_few_shot_sequential_chain(\n",
    "    config: List[Dict[str, Union[List[str],str]]],\n",
    "    examples_df: pd.DataFrame,\n",
    "    llm: langchain.llms.base.LLM,\n",
    "    variable_delimiter: str ='|||'\n",
    ") -> SequentialChain:\n",
    "\n",
    "  chain_elements = []\n",
    "  all_output_variables =[]\n",
    "  for stage_info in config:\n",
    "    input_variables = stage_info['input_variables']\n",
    "    output_variables = stage_info['output_variables']\n",
    "    prompt_prefix = stage_info['prompt_prefix']\n",
    "\n",
    "    prompt = make_few_shot_prompt(input_variables,\n",
    "                                  output_variables,\n",
    "                                  prompt_prefix,\n",
    "                                  examples_df,\n",
    "                                  variable_delimiter\n",
    "                                  )\n",
    "\n",
    "  # LLM is MISO. To make the each stage MIMO, we create a SequentialChain from\n",
    "  # the said LLMChain and a follow uup TransformChain that extracts the output\n",
    "  # variables from the LLMChain's output. Using an output parser did not work because\n",
    "  # the LLMChain can ultimately just return  one output.\n",
    "\n",
    "  def transform_func(inputs: Dict)-> Dict:\n",
    "    actual_vars_formatted = []\n",
    "    actual_vars_unformatted = inputs['text'].split(variable_delimiter)\n",
    "    for actual_var in actual_vars_unformatted:\n",
    "      if ':' in actual_var:\n",
    "        var_name, var_value = tuple(actual_var.split(':',1))\n",
    "        var_name = var_name.strip('\\n').strip()\n",
    "        var_value = var_value.strip('\\n').strip()\n",
    "        actual_vars_formatted.append((var_name, var_value))\n",
    "    return dict(actual_vars_formatted)\n",
    "\n",
    "  chain_element = SequentialChain(\n",
    "      input_variables = input_variables,\n",
    "      output_variables = output_variables,\n",
    "      chains = [\n",
    "          LLMChain(prompt = prompt, llm=llm),\n",
    "          TransformChain(\n",
    "              input_variables=['text'],output_variables=output_variables,\n",
    "              transform= transform_func\n",
    "            )\n",
    "      ]\n",
    "  )\n",
    "\n",
    "  chain_elements.append(chain_element)\n",
    "  all_output_variables.extend(output_variables)\n",
    "\n",
    "  full_chain = SequentialChain(\n",
    "      chains = chain_elements,\n",
    "      input_variables=chain_elements[0].input_variables,\n",
    "      output_variables=all_output_variables,\n",
    "  )\n",
    "  return full_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2Dy_M2KLNLnU"
   },
   "outputs": [],
   "source": [
    "def apply_chain_on_df(chain: SequentialChain,\n",
    "                      df: pd.DataFrame,\n",
    "                      output_suffix: str = '_out') -> pd.DataFrame:\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        [chain(row[chain.input_variables].to_dict())\n",
    "        for _,row in df.iterrows()],\n",
    "        index = df.index,\n",
    "    )\n",
    "    results_df = results_df[chain.output_variables]\n",
    "    results_df.columns = results_df.columns + f'{output_suffix}'\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wJJb410OOTCV"
   },
   "outputs": [],
   "source": [
    "def get_df_from_sheet_url(url:str,sheet_name) -> pd.DataFrame:\n",
    "  rows = gc.open_by_url(url)\n",
    "  worksheet = rows.worksheet(sheet_name)\n",
    "\n",
    "  df = pd.DataFrame(worksheet.get_all_records())\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6I7D9XLbdRL"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBJT9oaQOM8B"
   },
   "source": [
    "# Load Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "RnVHRcF5OKq9",
    "outputId": "a7068a72-9822-4862-92e0-1c5f55b7d85a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dynamic_hypothesis</th>\n",
       "      <th>variables</th>\n",
       "      <th>label_graphs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>The order rate decision, if it is to bring act...</td>\n",
       "      <td>order rate, inventory, desired inventory, adju...</td>\n",
       "      <td>digraph {\\n\"order rate\" -&gt; \"inventory\" [arrowh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>A hot cup of coffee will gradually cool down t...</td>\n",
       "      <td>coffee temperature, discrepancy, cooling rate,...</td>\n",
       "      <td>digraph {\\n\"coffee temperature\" -&gt; \"discrepanc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     dynamic_hypothesis  \\\n",
       "Case                                                      \n",
       "NaN   The order rate decision, if it is to bring act...   \n",
       "NaN   A hot cup of coffee will gradually cool down t...   \n",
       "\n",
       "                                              variables  \\\n",
       "Case                                                      \n",
       "NaN   order rate, inventory, desired inventory, adju...   \n",
       "NaN   coffee temperature, discrepancy, cooling rate,...   \n",
       "\n",
       "                                           label_graphs  \n",
       "Case                                                     \n",
       "NaN   digraph {\\n\"order rate\" -> \"inventory\" [arrowh...  \n",
       "NaN   digraph {\\n\"coffee temperature\" -> \"discrepanc...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prompts_df = get_df_from_sheet_url(URL, SHEET_NAME)\n",
    "prompts_df = pd.read_csv('prompts.csv', index_col= 0, dtype= 'str')\n",
    "display(prompts_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-SKGc_J0OsCM"
   },
   "outputs": [],
   "source": [
    "prompts_df['label_graphs'] = prompts_df['label_graphs'].str.replace(\n",
    "    '{','{{',regex = False\n",
    ").str.replace(\n",
    "    '}','}}',regex = False\n",
    ")\n",
    "\n",
    "prompts_df['dynamic_hypothesis'] = prompts_df['dynamic_hypothesis'].str.strip('\\n').str.strip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "NgVAb9YNSlSZ",
    "outputId": "dec6395f-2390-4747-ac91-95a46d7d61b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dynamic_hypothesis</th>\n",
       "      <th>variables</th>\n",
       "      <th>label_graphs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>The order rate decision, if it is to bring act...</td>\n",
       "      <td>order rate, inventory, desired inventory, adju...</td>\n",
       "      <td>digraph {{\\n\"order rate\" -&gt; \"inventory\" [arrow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     dynamic_hypothesis  \\\n",
       "Case                                                      \n",
       "NaN   The order rate decision, if it is to bring act...   \n",
       "\n",
       "                                              variables  \\\n",
       "Case                                                      \n",
       "NaN   order rate, inventory, desired inventory, adju...   \n",
       "\n",
       "                                           label_graphs  \n",
       "Case                                                     \n",
       "NaN   digraph {{\\n\"order rate\" -> \"inventory\" [arrow...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dynamic_hypothesis</th>\n",
       "      <th>variables</th>\n",
       "      <th>label_graphs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>A hot cup of coffee will gradually cool down t...</td>\n",
       "      <td>coffee temperature, discrepancy, cooling rate,...</td>\n",
       "      <td>digraph {{\\n\"coffee temperature\" -&gt; \"discrepan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     dynamic_hypothesis  \\\n",
       "Case                                                      \n",
       "NaN   A hot cup of coffee will gradually cool down t...   \n",
       "\n",
       "                                              variables  \\\n",
       "Case                                                      \n",
       "NaN   coffee temperature, discrepancy, cooling rate,...   \n",
       "\n",
       "                                           label_graphs  \n",
       "Case                                                     \n",
       "NaN   digraph {{\\n\"coffee temperature\" -> \"discrepan...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_percentage_slider = 50\n",
    "train_df, test_df = train_test_split(prompts_df, test_size = test_percentage_slider/100.0,\n",
    "                                     shuffle=False)\n",
    "\n",
    "display(train_df)\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "T2ch4iMETFqJ"
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key = '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')\n",
    "\n",
    "#use chatGPT\n",
    "\n",
    "full_chain = make_few_shot_sequential_chain(config, train_df, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQtiazHhXnAW"
   },
   "outputs": [],
   "source": [
    "# from langchain import HuggingFaceHub, LLMChain\n",
    "\n",
    "# # initialize Hub LLM\n",
    "# hub_llm = HuggingFaceHub(\n",
    "#         repo_id='google/flan-t5-xl',\n",
    "#     model_kwargs={'temperature':1e-10}\n",
    "# )\n",
    "# full_chain = make_few_shot_sequential_chain(config, train_df, hub_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "f-TtGEzVTNde",
    "outputId": "08c09fd6-4b4c-4acf-c759-d8fa3bb84b38"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dynamic_hypothesis</th>\n",
       "      <th>variables</th>\n",
       "      <th>label_graphs</th>\n",
       "      <th>label_graphs_out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>A hot cup of coffee will gradually cool down t...</td>\n",
       "      <td>coffee temperature, discrepancy, cooling rate,...</td>\n",
       "      <td>digraph {{\\n\"coffee temperature\" -&gt; \"discrepan...</td>\n",
       "      <td>digraph {\\n\"coffee temperature\" -&gt; \"discrepanc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     dynamic_hypothesis  \\\n",
       "Case                                                      \n",
       "NaN   A hot cup of coffee will gradually cool down t...   \n",
       "\n",
       "                                              variables  \\\n",
       "Case                                                      \n",
       "NaN   coffee temperature, discrepancy, cooling rate,...   \n",
       "\n",
       "                                           label_graphs  \\\n",
       "Case                                                      \n",
       "NaN   digraph {{\\n\"coffee temperature\" -> \"discrepan...   \n",
       "\n",
       "                                       label_graphs_out  \n",
       "Case                                                     \n",
       "NaN   digraph {\\n\"coffee temperature\" -> \"discrepanc...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = apply_chain_on_df(full_chain, test_df)\n",
    "results_df = pd.concat([test_df, results_df], axis = 1)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "z_2G9bchTnvY"
   },
   "outputs": [],
   "source": [
    "#Revert the escaping operation from earlier.\n",
    "results_df['label_graphs'] = results_df['label_graphs'].str.replace(\n",
    "    '{{','{', regex = False\n",
    ").str.replace(\n",
    "    '}}','}', regex = False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
